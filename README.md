# ConvBERT

## ç›®å½•

- [0. ä»“åº“ç»“æ„]()
- [1. ç®€ä»‹]()
- [2. æ•°æ®é›†å’Œå¤ç°ç²¾åº¦]()
- [3. å‡†å¤‡æ•°æ®ä¸ç¯å¢ƒ]()
    - [3.1 å‡†å¤‡ç¯å¢ƒ]()
    - [3.2 å‡†å¤‡æ•°æ®]()
    - [3.3 å‡†å¤‡æ¨¡å‹]()
- [4. å¼€å§‹ä½¿ç”¨]()
    - [4.1 æ¨¡å‹è®­ç»ƒ]()
    - [4.2 æ¨¡å‹è¯„ä¼°]()
    - [4.3 æ¨¡å‹é¢„æµ‹]()
- [5. æ¨¡å‹æ¨ç†éƒ¨ç½²]()
    - [5.1 åŸºäºInferenceçš„æ¨ç†]()
    - [5.2 åŸºäºServingçš„æœåŠ¡åŒ–éƒ¨ç½²]()
- [6. TIPCè‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬]()
- [7. æ³¨æ„]()
- [8. LICENSE]()
- [9. å‚è€ƒé“¾æ¥ä¸æ–‡çŒ®]()

## 0. ä»“åº“ç»“æ„
```bash
root:[./]
|--convbert_base_outputs
|      |--args.json
|      |--best.pdparams
|      |      |--model_config.json
|      |      |--model_state.pdparams
|      |      |--tokenizer_config.json
|      |      |--vocab.txt
|--convbert_infer
|      |--inference.pdiparams
|      |--inference.pdiparams.info
|      |--inference.pdmodel
|      |--tokenizer_config.json
|      |--vocab.txt
|--deploy
|      |--inference_python
|      |      |--infer.py
|      |      |--README.md
|      |--serving_python
|      |      |--config.yml
|      |      |--convbert_client
|      |      |      |--serving_client_conf.prototxt
|      |      |      |--serving_client_conf.stream.prototxt
|      |      |--convbert_server
|      |      |      |--inference.pdiparams
|      |      |      |--inference.pdmodel
|      |      |      |--serving_server_conf.prototxt
|      |      |      |--serving_server_conf.stream.prototxt
|      |      |--PipelineServingLogs
|      |      |      |--pipeline.log
|      |      |      |--pipeline.log.wf
|      |      |      |--pipeline.tracer
|      |      |--pipeline_http_client.py
|      |      |--ProcessInfo.json
|      |      |--README.md
|      |      |--web_service.py
|--images
|      |--convbert_framework.jpg
|      |--py_serving_client_results.jpg
|      |--py_serving_startup_visualization.jpg
|--LICENSE
|--output_inference_engine.npy
|--output_predict_engine.npy
|--paddlenlp
|--print_project_tree.py
|--README.md
|--requirements.txt
|--shell
|      |--export.sh
|      |--inference_python.sh
|      |--predict.sh
|      |--train.sh
|      |--train_dist.sh
|--test_tipc
|      |--common_func.sh
|      |--configs
|      |      |--ConvBERT
|      |      |      |--model_linux_gpu_normal_normal_serving_python_linux_gpu_cpu.txt
|      |      |      |--train_infer_python.txt
|      |--docs
|      |      |--test_serving.md
|      |      |--test_train_inference_python.md
|      |      |--tipc_guide.png
|      |      |--tipc_serving.png
|      |      |--tipc_train_inference.png
|      |--output
|      |      |--python_infer_cpu_usemkldnn_False_threads_null_precision_null_batchsize_null.log
|      |      |--python_infer_gpu_usetrt_null_precision_null_batchsize_null.log
|      |      |--results_python.log
|      |      |--results_serving.log
|      |      |--server_infer_gpu_pipeline_http_usetrt_null_precision_null_batchsize_1.log
|      |--README.md
|      |--test_serving.sh
|      |--test_train_inference_python.sh
|--tools
|      |--export_model.py
|      |--predict.py
|--train.log
|--train.py
```

## 1. ç®€ä»‹
**è®ºæ–‡:** [ConvBERT: Improving BERT with Span-based Dynamic Convolution](https://arxiv.org/abs/2008.02496)

æ‘˜è¦ï¼š åƒBERTåŠå…¶å˜ä½“è¿™æ ·çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹æœ€è¿‘åœ¨å„ç§è‡ªç„¶è¯­è¨€ç†è§£ä»»åŠ¡ä¸­å–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„è¡¨ç°ã€‚ç„¶è€Œï¼ŒBERTä¸¥é‡ä¾èµ–å…¨å±€è‡ªæ³¨æ„åŠ›å—ï¼Œå› æ­¤éœ€è¦å¤§é‡å†…å­˜å ç”¨å’Œè®¡ç®—æˆæœ¬ã€‚ è™½ç„¶å®ƒçš„æ‰€æœ‰æ³¨æ„åŠ›å¤´ä»å…¨å±€è§’åº¦æŸ¥è¯¢æ•´ä¸ªè¾“å…¥åºåˆ—ä»¥ç”Ÿæˆæ³¨æ„åŠ›å›¾ï¼Œä½†æˆ‘ä»¬è§‚å¯Ÿåˆ°ä¸€äº›å¤´åªéœ€è¦å­¦ä¹ å±€éƒ¨ä¾èµ–ï¼Œè¿™æ„å‘³ç€å­˜åœ¨è®¡ç®—å†—ä½™ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäºè·¨åº¦çš„åŠ¨æ€å·ç§¯æ¥ä»£æ›¿è¿™äº›è‡ªæ³¨æ„åŠ›å¤´ï¼Œä»¥ç›´æ¥å¯¹å±€éƒ¨ä¾èµ–æ€§è¿›è¡Œå»ºæ¨¡ã€‚æ–°çš„å·ç§¯å¤´ä¸å…¶ä½™çš„è‡ªæ³¨æ„åŠ›å¤´ä¸€èµ·å½¢æˆäº†ä¸€ä¸ªæ–°çš„æ··åˆæ³¨æ„åŠ›å—ï¼Œåœ¨å…¨å±€å’Œå±€éƒ¨ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­éƒ½æ›´æœ‰æ•ˆã€‚ æˆ‘ä»¬ä¸º BERT é…å¤‡äº†è¿™ç§æ··åˆæ³¨æ„åŠ›è®¾è®¡å¹¶æ„å»ºäº†ä¸€ä¸ªConvBERTæ¨¡å‹ã€‚å®éªŒè¡¨æ˜ï¼ŒConvBERT åœ¨å„ç§ä¸‹æ¸¸ä»»åŠ¡ä¸­æ˜æ˜¾ä¼˜äºBERTåŠå…¶å˜ä½“ï¼Œå…·æœ‰æ›´ä½çš„è®­ç»ƒæˆæœ¬å’Œæ›´å°‘çš„æ¨¡å‹å‚æ•°ã€‚ å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒConvBERT-base æ¨¡å‹è¾¾åˆ°86.4GLUEåˆ†æ•°ï¼Œæ¯”ELECTRA-baseé«˜0.7ï¼ŒåŒæ—¶ä½¿ç”¨ä¸åˆ°1/4çš„è®­ç»ƒæˆæœ¬ã€‚


<div align="center">
    <img src="./images/convbert_framework.jpg" width=800">
</div>

## 2. æ•°æ®é›†å’Œå¤ç°ç²¾åº¦

æ•°æ®é›†ä¸º`SST-2`ã€‚

| æ¨¡å‹      | sst-2 dev acc (å¤ç°ç²¾åº¦) |
|:---------:|:----------:|
| ConvBERT | 0.9461   |


## 3. å‡†å¤‡ç¯å¢ƒä¸æ•°æ®

### 3.1 å‡†å¤‡ç¯å¢ƒ

* ä¸‹è½½ä»£ç 

```bash
git clone https://github.com/junnyu/ConvBERT-Prod.git
```

* å®‰è£…paddlepaddle

```bash
# éœ€è¦å®‰è£…2.2åŠä»¥ä¸Šç‰ˆæœ¬çš„Paddleï¼Œå¦‚æœ
# å®‰è£…GPUç‰ˆæœ¬çš„Paddle
pip install paddlepaddle-gpu==2.2.0
# å®‰è£…CPUç‰ˆæœ¬çš„Paddle
pip install paddlepaddle==2.2.0
```

æ›´å¤šå®‰è£…æ–¹æ³•å¯ä»¥å‚è€ƒï¼š[Paddleå®‰è£…æŒ‡å—](https://www.paddlepaddle.org.cn/)ã€‚

* å®‰è£…requirements

```bash
pip install -r requirements.txt
```

### 3.2 å‡†å¤‡æ•°æ®

`SST-2`æ•°æ®å·²ç»é›†æˆåœ¨`paddlenlp`ä»“åº“ä¸­ã€‚

### 3.3 å‡†å¤‡æ¨¡å‹

å¦‚æœæ‚¨å¸Œæœ›ç›´æ¥ä½“éªŒè¯„ä¼°æˆ–è€…é¢„æµ‹æ¨ç†è¿‡ç¨‹ï¼Œå¯ä»¥ç›´æ¥æ ¹æ®ç¬¬2ç« çš„å†…å®¹ä¸‹è½½æä¾›çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œç›´æ¥ä½“éªŒæ¨¡å‹è¯„ä¼°ã€é¢„æµ‹ã€æ¨ç†éƒ¨ç½²ç­‰å†…å®¹ã€‚


## 4. å¼€å§‹ä½¿ç”¨

### 4.1 æ¨¡å‹è®­ç»ƒ

* å•æœºå•å¡è®­ç»ƒ

```bash
export CUDA_VISIBLE_DEVICES=0
python -m paddle.distributed.launch --gpus "0" train.py \
    --model_type convbert \
    --model_name_or_path convbert-base \
    --task_name sst-2 \
    --max_seq_length 128 \
    --learning_rate 1e-4 \
    --num_train_epochs 3 \
    --output_dir ./convbert_base_outputs/ \
    --logging_steps 100 \
    --save_steps 400 \
    --batch_size 32   \
    --warmup_proportion 0.1
```

éƒ¨åˆ†è®­ç»ƒæ—¥å¿—å¦‚ä¸‹æ‰€ç¤ºã€‚

```
====================================================================================================
global step 2500/6315, epoch: 1, batch: 394, rank_id: 0, loss: 0.140546, lr: 0.0000671182, speed: 3.7691 step/s
global step 2600/6315, epoch: 1, batch: 494, rank_id: 0, loss: 0.062813, lr: 0.0000653589, speed: 4.1413 step/s
global step 2700/6315, epoch: 1, batch: 594, rank_id: 0, loss: 0.051268, lr: 0.0000635996, speed: 4.1867 step/s
global step 2800/6315, epoch: 1, batch: 694, rank_id: 0, loss: 0.133289, lr: 0.0000618403, speed: 4.1769 step/s
eval loss: 0.342346, acc: 0.9461009174311926,
eval done total : 1.9056718349456787 s
====================================================================================================
```

* å•æœºå¤šå¡è®­ç»ƒ

```bash
export CUDA_VISIBLE_DEVICES=0,1,2,3
python -m paddle.distributed.launch --gpus "0,1,2,3" train.py \
    --model_type convbert \
    --model_name_or_path convbert-base \
    --task_name sst-2 \
    --max_seq_length 128 \
    --learning_rate 1e-4 \
    --num_train_epochs 3 \
    --output_dir ./convbert_base_outputs/ \
    --logging_steps 100 \
    --save_steps 400 \
    --batch_size 32   \
    --warmup_proportion 0.1
```

æ›´å¤šé…ç½®å‚æ•°å¯ä»¥å‚è€ƒ[train.py](./train.py)çš„`get_args_parser`å‡½æ•°ã€‚

### 4.2 æ¨¡å‹è¯„ä¼°

è¯¥é¡¹ç›®ä¸­ï¼Œè®­ç»ƒä¸è¯„ä¼°è„šæœ¬åŒæ—¶è¿›è¡Œï¼Œè¯·æŸ¥çœ‹è®­ç»ƒè¿‡ç¨‹ä¸­çš„è¯„ä»·æŒ‡æ ‡ã€‚

### 4.3 æ¨¡å‹é¢„æµ‹

* ä½¿ç”¨GPUé¢„æµ‹

```
python tools/predict.py --model_path=./convbert_base_outputs/best.pdparams
```

å¯¹äºä¸‹é¢çš„æ–‡æœ¬è¿›è¡Œé¢„æµ‹

`the problem , it is with most of these things , is the script .`

æœ€ç»ˆè¾“å‡ºç»“æœä¸º`label_id: 0, prob: 0.9959235191345215`ï¼Œè¡¨ç¤ºé¢„æµ‹çš„æ ‡ç­¾IDæ˜¯`0`ï¼Œç½®ä¿¡åº¦ä¸º`0.9959`ã€‚

* ä½¿ç”¨CPUé¢„æµ‹

```
python tools/predict.py --model_path=./convbert_base_outputs/best.pdparams --device=cpu
```
å¯¹äºä¸‹é¢çš„æ–‡æœ¬è¿›è¡Œé¢„æµ‹

`the problem , it is with most of these things , is the script .`

æœ€ç»ˆè¾“å‡ºç»“æœä¸º`label_id: 0, prob: 0.995919406414032`ï¼Œè¡¨ç¤ºé¢„æµ‹çš„æ ‡ç­¾IDæ˜¯`0`ï¼Œç½®ä¿¡åº¦ä¸º`0.9959`ã€‚

## 5. æ¨¡å‹æ¨ç†éƒ¨ç½²

### 5.1 åŸºäºInferenceçš„æ¨ç†

Inferenceæ¨ç†æ•™ç¨‹å¯å‚è€ƒï¼š[é“¾æ¥](./deploy/inference_python/README.md)ã€‚

### 5.2 åŸºäºServingçš„æœåŠ¡åŒ–éƒ¨ç½²

Servingéƒ¨ç½²æ•™ç¨‹å¯å‚è€ƒï¼š[é“¾æ¥](deploy/serving_python/README.md)ã€‚


## 6. TIPCè‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬

ä»¥LinuxåŸºç¡€è®­ç»ƒæ¨ç†æµ‹è¯•ä¸ºä¾‹ï¼Œæµ‹è¯•æµç¨‹å¦‚ä¸‹ã€‚

* è¿è¡Œæµ‹è¯•å‘½ä»¤

```bash
bash test_tipc/test_train_inference_python.sh test_tipc/configs/ConvBERT/train_infer_python.txt whole_train_whole_infer
```

å¦‚æœè¿è¡ŒæˆåŠŸï¼Œåœ¨ç»ˆç«¯ä¸­ä¼šæ˜¾ç¤ºä¸‹é¢çš„å†…å®¹ï¼Œå…·ä½“çš„æ—¥å¿—ä¹Ÿä¼šè¾“å‡ºåˆ°`test_tipc/output/`æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶ä¸­ã€‚

```
[33m Run successfully with command - python train.py --save_steps 400      --max_steps=6315           !  [0m
[33m Run successfully with command - python tools/export_model.py --model_path=./convbert_base_outputs/best.pdparams --save_inference_dir ./convbert_infer      !  [0m
[33m Run successfully with command - python deploy/inference_python/infer.py --model_dir ./convbert_infer --use_gpu=True               > ./test_tipc/output/python_infer_gpu_usetrt_null_precision_null_batchsize_null.log 2>&1 !  [0m
[33m Run successfully with command - python deploy/inference_python/infer.py --model_dir ./convbert_infer --use_gpu=False --benchmark=False               > ./test_tipc/output/python_infer_cpu_usemkldnn_False_threads_null_precision_null_batchsize_null.log 2>&1 !  [0m
```



* æ›´å¤šè¯¦ç»†å†…å®¹ï¼Œè¯·å‚è€ƒï¼š[ConvBERT TIPCæµ‹è¯•æ–‡æ¡£](./test_tipc/README.md)ã€‚
* å¦‚æœè¿è¡Œå¤±è´¥ï¼Œå¯ä»¥å…ˆæ ¹æ®æŠ¥é”™çš„å…·ä½“å‘½ä»¤ï¼Œè‡ªæŸ¥ä¸‹é…ç½®æ–‡ä»¶æ˜¯å¦æ­£ç¡®ï¼Œå¦‚æœæ— æ³•è§£å†³ï¼Œå¯ä»¥ç»™PaddleæISSUEï¼š[https://github.com/PaddlePaddle/Paddle/issues/new/choose](https://github.com/PaddlePaddle/Paddle/issues/new/choose)ï¼›å¦‚æœæ‚¨åœ¨å¾®ä¿¡ç¾¤é‡Œçš„è¯ï¼Œä¹Ÿå¯ä»¥åœ¨ç¾¤é‡ŒåŠæ—¶æé—®ã€‚

## 7. æ³¨æ„
ä¸ºäº†å¯ä»¥ä½¿ç”¨é™æ€å›¾å¯¼å‡ºåŠŸèƒ½ï¼Œæœ¬é¡¹ç›®ä¿®æ”¹äº†paddlenlpä»“åº“ä¸­çš„convbertæ¨¡å‹ï¼Œä¸»è¦ä¿®æ”¹éƒ¨åˆ†å¦‚ä¸‹ã€‚
- 1. ä½¿ç”¨`paddle.shape`è€Œä¸æ˜¯`tensor.shape`è·å–tensorçš„å½¢çŠ¶ã€‚
- 2. `F.unfold`å¯¹äºé™æ€å›¾ä¸æ€ä¹ˆå‹å¥½ï¼Œåªå¥½é‡‡ç”¨`for`å¾ªç¯ã€‚
```python
if self.conv_type == "sdconv":
    bs = paddle.shape(q)[0]
    seqlen = paddle.shape(q)[1]
    mixed_key_conv_attn_layer = self.key_conv_attn_layer(query)
    conv_attn_layer = mixed_key_conv_attn_layer * q

    # conv_kernel_layer
    conv_kernel_layer = self.conv_kernel_layer(conv_attn_layer)
    conv_kernel_layer = tensor.reshape(
        conv_kernel_layer, shape=[-1, self.conv_kernel_size, 1])
    conv_kernel_layer = F.softmax(conv_kernel_layer, axis=1)
    conv_out_layer = self.conv_out_layer(query)
    conv_out_layer = paddle.stack(
        [
            paddle.slice(F.pad(conv_out_layer, pad=[
                            self.padding, self.padding], data_format="NLC"), [1], starts=[i], ends=[i+seqlen])
            for i in range(self.conv_kernel_size)
        ],
        axis=-1,
    )
    conv_out_layer = tensor.reshape(
        conv_out_layer,
        shape=[-1, self.head_dim, self.conv_kernel_size])
    conv_out_layer = tensor.matmul(conv_out_layer, conv_kernel_layer)
    conv_out = tensor.reshape(
        conv_out_layer,
        shape=[bs, seqlen, self.num_heads, self.head_dim])
```

## 8. LICENSE

æœ¬é¡¹ç›®çš„å‘å¸ƒå—[Apache 2.0 license](./LICENSE)è®¸å¯è®¤è¯ã€‚

## 9. å‚è€ƒé“¾æ¥ä¸æ–‡çŒ®

TODO
