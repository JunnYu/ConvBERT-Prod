# PaddleServingé¢„æµ‹åŠŸèƒ½æµ‹è¯•

PaddleServingé¢„æµ‹åŠŸèƒ½æµ‹è¯•çš„ä¸»ç¨‹åºä¸º`test_serving.sh`ï¼Œå¯ä»¥æµ‹è¯•åŸºäºPaddleServingçš„éƒ¨ç½²åŠŸèƒ½ã€‚

## 1. æµ‹è¯•ç»“è®ºæ±‡æ€»

åŸºäºè®­ç»ƒæ˜¯å¦ä½¿ç”¨é‡åŒ–ï¼Œè¿›è¡Œæœ¬æµ‹è¯•çš„æ¨¡å‹å¯ä»¥åˆ†ä¸º`æ­£å¸¸æ¨¡å‹`å’Œ`é‡åŒ–æ¨¡å‹`ï¼Œè¿™ä¸¤ç±»æ¨¡å‹å¯¹åº”çš„Servingé¢„æµ‹åŠŸèƒ½æ±‡æ€»å¦‚ä¸‹ï¼š

| æ¨¡å‹ç±»å‹ |device | batchsize | tensorrt | mkldnn | cpuå¤šçº¿ç¨‹ |
|  ----   |  ---- |   ----   |  :----:  |   :----:   |  :----:  |
| æ­£å¸¸æ¨¡å‹ | GPU | 1 | - | - | - |

## 2. æµ‹è¯•æµç¨‹

### 2.1 å‡†å¤‡ç¯å¢ƒ

* é¦–å…ˆå‡†å¤‡dockerç¯å¢ƒï¼ŒAIStudioç¯å¢ƒå·²ç»å®‰è£…äº†åˆé€‚çš„dockerã€‚å¦‚æœæ˜¯éAIStudioç¯å¢ƒï¼Œè¯·[å‚è€ƒæ–‡æ¡£](https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.3/doc/doc_ch/environment.md)ä¸­çš„ "1.3.2 Dockerç¯å¢ƒé…ç½®" å®‰è£…dockerç¯å¢ƒã€‚

* ç„¶åå®‰è£…Paddle Servingä¸‰ä¸ªå®‰è£…åŒ…ï¼Œpaddle-serving-serverï¼Œpaddle-serving-client å’Œ paddle-serving-appã€‚

```bash
wget https://paddle-serving.bj.bcebos.com/test-dev/whl/paddle_serving_server_gpu-0.7.0.post102-py3-none-any.whl
pip install paddle_serving_server_gpu-0.7.0.post102-py3-none-any.whl

wget https://paddle-serving.bj.bcebos.com/test-dev/whl/paddle_serving_client-0.7.0-cp37-none-any.whl
pip install paddle_serving_client-0.7.0-cp37-none-any.whl

wget https://paddle-serving.bj.bcebos.com/test-dev/whl/paddle_serving_app-0.7.0-py3-none-any.whl
pip install paddle_serving_app-0.7.0-py3-none-any.whl
```

å¦‚æœå¸Œæœ›è·å–Paddle Serving Serveræ›´å¤šä¸åŒè¿è¡Œç¯å¢ƒçš„whlåŒ…ä¸‹è½½åœ°å€ï¼Œè¯·å‚è€ƒï¼š[ä¸‹è½½é¡µé¢](https://github.com/PaddlePaddle/Serving/blob/v0.7.0/doc/Latest_Packages_CN.md)


### 2.2 å‡†å¤‡æ¨¡å‹

ä¸‹è½½inferenceæ¨¡å‹åˆ°`ConvBERT_paddle`ç›®å½•ï¼Œ

```bash
ä»ç™¾åº¦äº‘ä¸‹è½½convbert_infer.zipï¼Œå½“ç„¶ä¹Ÿå¯ä»¥è‡ªå·±è®­ç»ƒç„¶åè½¬æ¢ã€‚ #TODO
# æ‚¨ä¹Ÿå¯ä»¥å°†inferenceæ¨¡å‹æ”¾åœ¨å½“å‰æ–‡ä»¶å¤¹ï¼Œå‹ç¼©åä¸Šä¼ è‡³githubï¼Œç„¶åä½¿ç”¨ä¸‹é¢çš„å‘½ä»¤è§£å‹
unzip convbert_infer.zip
```

### 2.3 æµ‹è¯•åŠŸèƒ½

è¿è¡Œ`test_serving.sh`è¿›è¡Œæµ‹è¯•ï¼Œæœ€ç»ˆåœ¨`test_tipc/output`ç›®å½•ä¸‹ç”Ÿæˆ`serving_infer_*.log`åç¼€çš„æ—¥å¿—æ–‡ä»¶ã€‚

```bash
bash test_tipc/test_serving.sh ./test_tipc/configs/ConvBERT/model_linux_gpu_normal_normal_serving_python_linux_gpu_cpu.txt
```  

#### è¿è¡Œç»“æœ

<div align="center">
    <img src="./tipc_serving.png" width=800">
</div>

å„æµ‹è¯•çš„è¿è¡Œæƒ…å†µä¼šæ‰“å°åœ¨ `test_tipc/output/results_serving.log` ä¸­ï¼š
è¿è¡ŒæˆåŠŸæ—¶ä¼šè¾“å‡ºï¼š

```
[33m Run successfully with command - python pipeline_http_client.py  > ../../test_tipc/output/server_infer_gpu_pipeline_http_usetrt_null_precision_null_batchsize_1.log 2>&1!  [0m
...
```

è¿è¡Œå¤±è´¥æ—¶ä¼šè¾“å‡ºï¼š

```
[33m Run failed with command - python pipeline_http_client.py  > ../../test_tipc/output/server_infer_gpu_pipeline_http_usetrt_null_precision_null_batchsize_1.log 2>&1!  [0m
Run failed with command - xxxxx
...
```

è¯¦ç»†çš„é¢„æµ‹ç»“æœä¼šå­˜åœ¨ test_tipc/output/ æ–‡ä»¶å¤¹ä¸‹ï¼Œä¾‹å¦‚`server_infer_gpu_pipeline_http_usetrt_null_precision_null_batchsize_1.log`ä¸­ä¼šè¿”å›ç±»åˆ«IDä»¥åŠç½®ä¿¡åº¦:

```
{'err_no': 0, 'err_msg': '', 'key': ['label_id', 'prob'], 'value': ['[0]', '[0.99591]'], 'tensors': []}
```

## 3. æ›´å¤šæ•™ç¨‹

æœ¬æ–‡æ¡£ä¸ºåŠŸèƒ½æµ‹è¯•ç”¨ï¼Œæ›´è¯¦ç»†çš„Servingé¢„æµ‹ä½¿ç”¨æ•™ç¨‹è¯·å‚è€ƒï¼š[ConvBERT æœåŠ¡åŒ–éƒ¨ç½²](../../deploy/serving/README.md)  
